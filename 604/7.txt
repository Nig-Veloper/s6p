#AIM: WAP to parse XML text, generate web graph and compute topics of specific page.

#THEORY:

XML: XML stands for eXtensible Markup Language. It was designed to store and transport data. It was
designed to be both human- and machine-readable. That’s why, the design goals of XML emphasize
simplicity, generality, and usability across the Internet.
The XML file to be parsed in this tutorial is actually a RSS feed.

RSS: RSS(Rich Site Summary, often called Really Simple Syndication) uses a family of standard web feed
formats to publish frequently updated information like blog entries, news headlines, audio, video. RSS is
XML formatted plain text.
The code will:
• Load RSS feed from specified URL and save it as an XML file.
• Parse the XML file to save news as a list of dictionaries where each dictionary is a single news item.
• Save the news items into a CSV file.

Loading and saving RSS feed:
Here, we first created a HTTP response object by sending an HTTP request to the URL of the RSS feed.
The content of response now contains the XML file data which we save as topnewsfeed.xml in our local
directory.

Parsing XML:
We have created parseXML() function to parse XML file. We know that XML is an inherently hierarchical
data format, and the most natural way to represent it is with a tree.
Here, we are using xml.etree.ElementTree (call it ET, in short) module. Element Tree has two classes for
this purpose – ElementTree represents the whole XML
document as a tree, and Element represents a single node in this tree. Interactions with the whole
document (reading and writing to/from files) are usually done on the ElementTree level. Interactions
with a single XML element and its sub-elements are done on the Element level.
getroot() function return the root of tree as an Element object.

./channel/item is actually XPath syntax (XPath is a language for addressing parts of an XML document).
Here, we want to find all item grand-children of channel children of the root(denoted by ‘.’) element.
Now, we know that we are iterating through item elements where each item element contains one
news. So, we create an empty news dictionary in which we will store all data available about news item.
To iterate though each child element of an element, we simply iterate through it.
child.attrib is a dictionary of all the attributes related to an element. Here, we are interested
in url attribute of media:content namespace tag.
child.tag contains the name of child element. child.text stores all the text inside that child element.
Then, we simply append this dict element to the list newsitems.

Saving data to a CSV file:
Now, we simply save the list of news items to a CSV file so that it could be used or modified easily in
future using savetoCSV() function.

#CODE:

import requests
import xml.etree.ElementTree as ET
import csv
def loadRSS():
# url of rss feed
url = 'http://hindustantimes.com/rss/topnews/rssfeed.xml'
# creating HTTP response object from given url
resp = requests.get(url)
# saving the xml file
with open('topnewsfeed.xml', 'wb') as f:
f.write(resp.content)
def parseXML(xmlfile):
# create element tree object
tree = ET.parse(xmlfile)
# get root element
root = tree.getroot()
# create empty list for news items
newsitems = []
# iterate news items
for item in root.findall('./channel/item'):
# empty news dictionary
news = {}

# iterate child elements of item
for child in item:
# special checking for namespace object content:media
if child.tag == '{http://search.yahoo.com/mrss/}content':
news['media'] = child.attrib['url']
elif child.text is not None:
news[child.tag] = child.text.encode('utf-8')
else:
newsitems.append(news)
# return news items list
return newsitems
def savetoCSV(newsitems, filename):
# specifying the fields for csv file
fields = ['guid', 'title', 'pubDate', 'description', 'link', 'media']
# writing to csv file
with open(filename, 'w') as csvfile:
# creating a csv dict writer object
writer = csv.DictWriter(csvfile, fieldnames=fields)
# writing headers (field names)
writer.writeheader()
# writing data rows
writer.writerows(newsitems)
# load rss from web to update existing xml file
loadRSS()
# parse xml file
newsitems = parseXML('topnewsfeed.xml')
# store news items in a csv file
savetoCSV(newsitems, 'topnews.csv')